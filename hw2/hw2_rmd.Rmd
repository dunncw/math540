---
title: "hw2"
author: "cayden dunn"
date: "2022-10-27"
output: html_document
---
#get data
```{r}
b_housing <- read.csv("/Users/cindydunn/Desktop/Grad_School/math540/hw2/data/BostonHousing.csv")

b_housing$CAT..MEDV <- as.factor(b_housing$CAT..MEDV) # factor with 2 levels
levels(b_housing$CAT..MEDV) <- c("no", "yes") # redefine levels

## Include the functions required for data partitioning
source("/Users/cindydunn/Desktop/Grad_School/math540/hw2/myfunctions copy.r")
#remove MEDV from the data set
b_housing <- b_housing[,-13]
```


# A. Split the data into training (80%) and test (20%) datasets.
# Create training validation test data

```{r}
RNGkind (sample.kind = "Rounding") 
set.seed(123) ## set seed so that you get same partition each time
p2 <- partition.2(b_housing, 0.8) ## creating 80:20 partition
training.data <- p2$data.train # training data
test.data <- p2$data.test # test data
```


#1. Build a k-nearest neighbor model. Clearly show the model building steps for full credit. What is the optimal number of neighbors?

1 is the best k
```{r}

### Rescale the data
#center is the mean of each column
#scale is the standard deviation of each column
# the -9 drops that coulmn from the dataframe
training.scaled <- scale(training.data[,-13], center = TRUE, scale = TRUE) # exclude the response vairable from the data set for scaling
training.scaled.wY <- cbind(training.scaled, training.data[,13])
training.scaled.attr <- attributes(training.scaled)
test.scaled <- scale(test.data[,-13], 
                    center = training.scaled.attr$`scaled:center`, 
                    scale = training.scaled.attr$`scaled:scale`)

library(FNN)
library(caret)
### fit k-nn model for k = 1, ..., 100
K <- 100
kappa <- rep(0, K)
for (kk in 1:K){
  Knn <- knn(train = training.scaled, test = test.scaled,
             cl = training.data[,13], k = kk)
  c <- confusionMatrix(as.factor(Knn), as.factor(test.data[,13]), 
                       positive = "yes")
  kappa[kk] <- c$overall["Kappa"]
  #cat("K", kk, "Kappa", kappa[kk], "\n")
}

# create a plot for k vs. kappa
plot(c(1:K), kappa, xlab = "k", ylab = "Kappa", type = "l", col = "blue")

which.max((kappa)) # the best k
# we are looking for the largest kappa value
```

# 2. Evaluate the predictive performance of this model on the test data.

Prediction no yes
       no  83   3
       yes  1  14

Accuracy : 0.9604
Sensitivity : 0.8235
Specificity : 0.9881

```{r}
### fit k-nn model on test data with k=1
Knn <- knn(train = training.scaled, test = test.scaled,
           cl = training.data[,13], k = 1)
confusionMatrix(as.factor(Knn), as.factor(test.data[,13]), 
                positive = "yes")
```

# B. Use the BostonHousing data to accomplish the following modeling tasks.
#gonna rest the data just to make sure nothing gets messed up
```{r}
b_housing <- read.csv("/Users/cindydunn/Desktop/Grad_School/math540/hw2/data/BostonHousing.csv")

b_housing$CAT..MEDV <- as.factor(b_housing$CAT..MEDV) # factor with 2 levels
levels(b_housing$CAT..MEDV) <- c("no", "yes") # redefine levels

#remove MEDV from the data set
b_housing <- b_housing[,-13]

# A. Split the data into training (80%) and test (20%) datasets.
# Create training validation test data
RNGkind (sample.kind = "Rounding") 
set.seed(123) ## set seed so that you get same partition each time
p2 <- partition.2(b_housing, 0.8) ## creating 80:20 partition
training.data <- p2$data.train # training data
test.data <- p2$data.test # test data
```
## 1. Fit a classification tree using cost complexity pruning. Clearly show the model building steps for full credit.
```{r}
library(rpart)
library(rpart.plot)
# fit classification tree on training data
# minsplit refers to the minimum number of observations that must exist 
# in a node in order for a split to be attempted. The default value is 20. 
# minbucket argument can be specified to indicate the minimum number of 
# required observations in the terminal nodes for the split to happen.
ct1 <- rpart(CAT..MEDV ~ . , data = training.data, method = "class", 
             minsplit=15, minbucket = 5)
#minsplit - minimum number of observations in a node for a split to be attempted
#minbucket - minimum number of observations in a terminal node for a split to to be valid
# Ex. if u split a node with 16 observations, and get 2 terminal nodes with 13 observations and 3 then the split is not valid as 3 is less than minbucket,
```


# plot tree
```{r}
prp(ct1, type = 1, extra = 1, under = TRUE, split.font = 2, varlen = -10)
```

# variable importance
```{r}
ct1$variable.importance
```

#2. Write down the results in terms of rules. (i.e. for each terminal node, write down the decision and list the conditions that must be followed to reach that decision)
```{r}
summary(ct1)
```
When creating a decsion tree there are two conditions that dictate how terminal nodes are created and these two paramters are minsplit and minbucket. These terms are defined below and the values passed for this decesion tree are minsplit=15, minbucket = 5.
minsplit - minimum number of observations in a node for a split to be attempted
minbucket - minimum number of observations in a terminal node for a split to to be valid

 1) root 405 67 no (0.83456790 0.16543210)
   2) RM< 6.941 347 15 no (0.95677233 0.04322767)  
     4) LSTAT>=5.055 329  6 no (0.98176292 0.01823708) * 329 observations this passes the minsplit constraint this must have failed min bucket when this node was attempted to be split
     5) LSTAT< 5.055 18  9 no (0.50000000 0.50000000)  
      10) RM< 6.687 11  3 no (0.72727273 0.27272727) * 11 observations in this node fails minsplit constraint so it cannot be split any further
      11) RM>=6.687 7  1 yes (0.14285714 0.85714286) * 7 observations in this  node fails minsplit constraint so it cannot be split any further
   3) RM>=6.941 58  6 yes (0.10344828 0.89655172) 
     6) PTRATIO>=19.65 5  1 no (0.80000000 0.20000000) * 5 observations in this node fails minsplit constraint so it cannot be split any further
     7) PTRATIO< 19.65 53  2 yes (0.03773585 0.96226415) * 53 observations this passes the minsplit constraint this must have failed min bucket when this node was attemped to be split

# check to see how the model preformed
```{r}
pred.test = predict(ct1, test.data, type = 'class')

# create confusion matrix
library(caret)
confusionMatrix(pred.test, test.data$CAT..MEDV, positive = "yes")
```

Prediction no yes
       no  80   2
       yes  4  15

Accuracy : 0.9406 
Sensitivity : 0.8824          
Specificity : 0.9524
Kappa : 0.7973 

The model preforms well

# C. Compare the performances of the two models that you built in this assignment.

The models preform around the same with model 1(kNN) besting model two in overall model accuracy by a difference of 0.2. Besides this metric model 1 and two have varying scores for Sensitivity and Specificity. With model 1 being more specific and model 2 being more sensitive. However for this dataset both of the models perform very well and I would rule neither out as a method of analying/modeling the given dataset. And if I was forced to chose an approach that is best i would chose model 1. Model 1's kappa value is also siginifigantly better than model 2's kappa value and this is yet another reason to select model 1

Model 1's performance 

Prediction no yes
       no  83   3
       yes  1  14

Accuracy : 0.9604
Sensitivity : 0.8235
Specificity : 0.9881
Kappa : 0.8516 


model 2's preformance

Prediction no yes
       no  80   2
       yes  4  15

Accuracy : 0.9406 
Sensitivity : 0.8824          
Specificity : 0.9524
Kappa : 0.7973 





